{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ae429383",
      "metadata": {
        "id": "ae429383"
      },
      "source": [
        "# Assignment 4: Quantum Channel Classification\n",
        "We reuse the Week 3 classifier to tag noisy channels quickly during calibration checks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8f1393a",
      "metadata": {
        "id": "a8f1393a"
      },
      "source": [
        "This week we focus on applying the saved classifier and showing that the workflow runs end to end.\n",
        "\n",
        "**Task plan**\n",
        "1. Explain why quick channel labels matter and list the workflow you will follow.\n",
        "2. Load the helper code, pull in the trained estimator, and note any backup plan.\n",
        "3. Rebuild the feature mapper from Kraus operators to Choi vectors.\n",
        "4. Test the model on a small batch of synthetic channels and record observations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fe3bfc",
      "metadata": {
        "id": "17fe3bfc"
      },
      "source": [
        "## Background notes\n",
        "- A quantum channel $\\mathcal{E}$ is a completely positive, trace-preserving map. We write $\\mathcal{E}(\\rho) = \\sum_k K_k \\rho K_k^\\dagger$ with $\\sum_k K_k^\\dagger K_k = I$ so that each Kraus operator $K_k$ captures one noise branch.\n",
        "- The Choi matrix $C_{\\mathcal{E}} = (\\mathcal{E} \\otimes I)(|\\Phi^+\\rangle\\langle\\Phi^+|)$ models how the channel acts on half of an entangled pair. Flattening its real and imaginary parts gives a steady feature vector.\n",
        "- Classification is lighter than full tomography. We only emit labels like depolarising or amplitude damping, which keeps the calibration loop fast."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ansul1214/Open_Project_Winter_2025.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFeLaAoFxL_w",
        "outputId": "52ac4969-189d-4be3-b7a5-ebdf33a489f6"
      },
      "id": "jFeLaAoFxL_w",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Open_Project_Winter_2025'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 165 (delta 40), reused 12 (delta 12), pack-reused 82 (from 2)\u001b[K\n",
            "Receiving objects: 100% (165/165), 502.99 KiB | 8.98 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e9ebb7",
      "metadata": {
        "id": "c4e9ebb7"
      },
      "source": [
        "## Task 1 · Environment check\n",
        "- Confirm qiskit, numpy, pandas, joblib, and scikit-learn import without errors.\n",
        "- If anything is missing, run the pip cell below and log the command in your notes.\n",
        "- Once the imports work, move to Task 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7c655110-913a-46fa-9731-49d2ae9ecd4e",
        "id": "e4UW5ILixQET"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qiskit NOT installed.\n",
            "numpy imported successfully.\n",
            "pandas imported successfully.\n",
            "joblib imported successfully.\n",
            "sklearn imported successfully.\n",
            "\n",
            "Missing packages detected: ['qiskit']\n"
          ]
        }
      ],
      "source": [
        "# Log your environment status here once Task 1 is complete.\n",
        "required_packages = [\n",
        "    \"qiskit\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"joblib\",\n",
        "    \"sklearn\"\n",
        "]\n",
        "\n",
        "missing = []\n",
        "\n",
        "for pkg in required_packages:\n",
        "    try:\n",
        "        __import__(pkg)\n",
        "        print(f\"{pkg} imported successfully.\")\n",
        "    except ImportError:\n",
        "        print(f\"{pkg} NOT installed.\")\n",
        "        missing.append(pkg)\n",
        "\n",
        "if missing:\n",
        "    print(\"\\nMissing packages detected:\", missing)\n",
        "else:\n",
        "    print(\"\\nAll required packages imported successfully.\")\n"
      ],
      "id": "e4UW5ILixQET"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "586eca15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "586eca15",
        "outputId": "ef9f5219-2e89-4980-96bb-e9de3445e8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.3.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Downloading qiskit-2.3.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit\n",
            "Successfully installed qiskit-2.3.0 rustworkx-0.17.1 stevedore-5.6.0\n"
          ]
        }
      ],
      "source": [
        "# Install prerequisites if the kernel is missing a package.\n",
        "# !pip install qiskit scikit-learn joblib pandas\n",
        "!pip install qiskit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab6fb9c",
      "metadata": {
        "id": "5ab6fb9c"
      },
      "source": [
        "## Task 2 · Import helper modules\n",
        "- Run the cell below to pull in numpy, joblib, qiskit, pandas, and os.\n",
        "- Keep the imports in one place so later tasks stay consistent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "681f2e42",
      "metadata": {
        "id": "681f2e42"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from qiskit.quantum_info import Kraus, Choi\n",
        "import pandas as pd\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Open_Project_Winter_2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_u8nT_VyOl4",
        "outputId": "10466999-e99b-47f9-a418-8ef86580bed5"
      },
      "id": "h_u8nT_VyOl4",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Open_Project_Winter_2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load trained classifier from Assignment_3\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from qiskit.quantum_info import Kraus, Choi\n",
        "\n",
        "model_path = \"Assignment_3/channel_classifier.pkl\"\n",
        "\n",
        "print(\"Checking model path:\", model_path)\n",
        "print(\"File exists:\", os.path.exists(model_path))\n",
        "\n",
        "try:\n",
        "    model = joblib.load(model_path)\n",
        "    print(\"\\nModel loaded successfully.\")\n",
        "    print(\"Model type:\", type(model))\n",
        "    print(\"Expected input features:\", model.n_features_in_)\n",
        "    print(\"Classes:\", model.classes_)\n",
        "except Exception as e:\n",
        "    print(\"Model loading failed:\", e)\n",
        "    model = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFhuvysexcoQ",
        "outputId": "6dd86f93-3a16-4834-8c2a-bdcd434cd914"
      },
      "id": "wFhuvysexcoQ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking model path: Assignment_3/channel_classifier.pkl\n",
            "File exists: True\n",
            "\n",
            "Model loaded successfully.\n",
            "Model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "Expected input features: 32\n",
            "Classes: ['amplitude_damping' 'depolarizing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fec7578d",
      "metadata": {
        "id": "fec7578d"
      },
      "source": [
        "## Task 3 · Build a calibration-time classifier\n",
        "- Implement a lightweight classifier that maps Choi features to channel labels without relying on saved artefacts.\n",
        "- Keep the training code inside the provided function so reviewers can see your modelling choices.\n",
        "- You may reuse utilities from earlier assignments (data loaders, feature encoders) as long as they are imported inside the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09683c19",
      "metadata": {
        "id": "09683c19"
      },
      "outputs": [],
      "source": [
        "def build_channel_classifier():\n",
        "    \"\"\"\n",
        "    TODO: Train and return a classifier that distinguishes the channel families used in this exercise.\n",
        "\n",
        "    Suggested steps:\n",
        "        1. Create or load a labelled dataset of Choi features (can reuse helpers from Assignment 3).\n",
        "        2. Split into train/validation sets to tune hyperparameters if needed.\n",
        "        3. Fit a simple baseline model (e.g., logistic regression, random forest) and report key metrics via prints.\n",
        "        4. Return the trained estimator so downstream cells can call `predict`.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"Implement the calibration-time classifier for Task 3.\")\n",
        "\n",
        "model = build_channel_classifier()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_channel_classifier():\n",
        "\n",
        "    import numpy as np\n",
        "    from qiskit.quantum_info import Kraus, Choi\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "    # Channel definitions\n",
        "\n",
        "    def depolarizing_kraus(p):\n",
        "        k0 = np.sqrt(1 - 3*p/4) * np.eye(2)\n",
        "        k1 = np.sqrt(p/4) * np.array([[0, 1], [1, 0]])\n",
        "        k2 = np.sqrt(p/4) * np.array([[0, -1j], [1j, 0]])\n",
        "        k3 = np.sqrt(p/4) * np.array([[1, 0], [0, -1]])\n",
        "        return Kraus([k0, k1, k2, k3])\n",
        "\n",
        "    def amplitude_damping_kraus(gamma):\n",
        "        k0 = np.array([[1, 0], [0, np.sqrt(1-gamma)]], dtype=complex)\n",
        "        k1 = np.array([[0, np.sqrt(gamma)], [0, 0]], dtype=complex)\n",
        "        return Kraus([k0, k1])\n",
        "\n",
        "\n",
        "    # Feature mapper\n",
        "\n",
        "    def channel_to_feature(channel):\n",
        "        choi = Choi(channel).data\n",
        "        real_part = np.real(choi).flatten()\n",
        "        imag_part = np.imag(choi).flatten()\n",
        "        return np.concatenate([real_part, imag_part])\n",
        "\n",
        "    # Dataset generation\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    params = np.linspace(0.05, 0.9, 40)\n",
        "\n",
        "    for p in params:\n",
        "        X.append(channel_to_feature(depolarizing_kraus(p)))\n",
        "        y.append(\"depolarizing\")\n",
        "\n",
        "    for g in params:\n",
        "        X.append(channel_to_feature(amplitude_damping_kraus(g)))\n",
        "        y.append(\"amplitude_damping\")\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "\n",
        "    # Train / Validation split\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "\n",
        "    # Baseline model\n",
        "\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=150,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Validation performance\n",
        "\n",
        "    val_preds = clf.predict(X_val)\n",
        "\n",
        "    print(\"\\n=== Calibration-Time Classifier Performance ===\")\n",
        "    print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, val_preds))\n",
        "\n",
        "    print(\"Feature dimension:\", clf.n_features_in_)\n",
        "    print(\"Classes:\", clf.classes_)\n",
        "\n",
        "    return clf\n"
      ],
      "metadata": {
        "id": "g-JRKc95zD7g"
      },
      "id": "g-JRKc95zD7g",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_channel_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSY_j7SVzrFT",
        "outputId": "4953e78c-7134-466e-d47c-d3d71978f1ca"
      },
      "id": "zSY_j7SVzrFT",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Calibration-Time Classifier Performance ===\n",
            "Validation Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "amplitude_damping       1.00      1.00      1.00        10\n",
            "     depolarizing       1.00      1.00      1.00        10\n",
            "\n",
            "         accuracy                           1.00        20\n",
            "        macro avg       1.00      1.00      1.00        20\n",
            "     weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "Feature dimension: 32\n",
            "Classes: ['amplitude_damping' 'depolarizing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33773f47",
      "metadata": {
        "id": "33773f47"
      },
      "source": [
        "## Task 4 · Build channel features\n",
        "- Regenerate the Kraus operators you used during training or adapt them for this demo.\n",
        "- Ensure `channel_to_feature` outputs the same ordering the model expects (real part first, imaginary part second)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5796adfd",
      "metadata": {
        "id": "5796adfd"
      },
      "outputs": [],
      "source": [
        "I = np.eye(2, dtype=complex)\n",
        "X = np.array([[0, 1], [1, 0]], dtype=complex)\n",
        "Y = np.array([[0, -1j], [1j, 0]], dtype=complex)\n",
        "Z = np.array([[1, 0], [0, -1]], dtype=complex)\n",
        "\n",
        "def depolarizing_kraus(p):\n",
        "    k0 = np.sqrt(1 - p) * I\n",
        "    k1 = np.sqrt(p/3) * X\n",
        "    k2 = np.sqrt(p/3) * Y\n",
        "    k3 = np.sqrt(p/3) * Z\n",
        "    return Kraus([k0, k1, k2, k3])\n",
        "\n",
        "def amplitude_damping_kraus(gamma):\n",
        "    k0 = np.array([[1, 0], [0, np.sqrt(1-gamma)]], dtype=complex)\n",
        "    k1 = np.array([[0, np.sqrt(gamma)], [0, 0]], dtype=complex)\n",
        "    return Kraus([k0, k1])\n",
        "\n",
        "def channel_to_feature(channel):\n",
        "    choi = Choi(channel).data\n",
        "    feat = np.concatenate([choi.real.flatten(), choi.imag.flatten()])\n",
        "    return feat\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from qiskit.quantum_info import Kraus, Choi\n",
        "\n",
        "def depolarizing_kraus(p):\n",
        "    k0 = np.sqrt(1 - 3*p/4) * np.eye(2)\n",
        "    k1 = np.sqrt(p/4) * np.array([[0, 1], [1, 0]])\n",
        "    k2 = np.sqrt(p/4) * np.array([[0, -1j], [1j, 0]])\n",
        "    k3 = np.sqrt(p/4) * np.array([[1, 0], [0, -1]])\n",
        "    return Kraus([k0, k1, k2, k3])\n",
        "\n",
        "def amplitude_damping_kraus(gamma):\n",
        "    k0 = np.array([[1, 0], [0, np.sqrt(1-gamma)]], dtype=complex)\n",
        "    k1 = np.array([[0, np.sqrt(gamma)], [0, 0]], dtype=complex)\n",
        "    return Kraus([k0, k1])\n",
        "\n",
        "def channel_to_feature(channel):\n",
        "    choi = Choi(channel).data\n",
        "    real_part = np.real(choi).flatten()\n",
        "    imag_part = np.imag(choi).flatten()\n",
        "    return np.concatenate([real_part, imag_part])\n"
      ],
      "metadata": {
        "id": "qL1bFlqD10hY"
      },
      "id": "qL1bFlqD10hY",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dede3a32",
      "metadata": {
        "id": "dede3a32"
      },
      "source": [
        "## Task 5 · Classify sample channels\n",
        "- Build a small list of synthetic channels, convert them with `channel_to_feature`, and stack the results in `X`.\n",
        "- Use the loaded model to predict labels and review the DataFrame for any surprising cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa644aac",
      "metadata": {
        "id": "aa644aac"
      },
      "outputs": [],
      "source": [
        "channels = [\n",
        "    ('depolarizing_p0.1', depolarizing_kraus(0.1)),\n",
        "    ('depolarizing_p0.5', depolarizing_kraus(0.5)),\n",
        "    ('amp_damp_0.1', amplitude_damping_kraus(0.1)),\n",
        "    ('amp_damp_0.5', amplitude_damping_kraus(0.5)),\n",
        "]\n",
        "\n",
        "features = []\n",
        "names = []\n",
        "for name, ch in channels:\n",
        "    f = channel_to_feature(ch)\n",
        "    names.append(name)\n",
        "    features.append(f)\n",
        "X = np.vstack(features)\n",
        "\n",
        "preds = model.predict(X)\n",
        "df = pd.DataFrame({'channel': names, 'prediction': preds})\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 5 — Classify Sample Channels\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Build small synthetic batch\n",
        "channels = [\n",
        "    ('depolarizing_p0.1', depolarizing_kraus(0.1)),\n",
        "    ('depolarizing_p0.5', depolarizing_kraus(0.5)),\n",
        "    ('amp_damp_0.1', amplitude_damping_kraus(0.1)),\n",
        "    ('amp_damp_0.5', amplitude_damping_kraus(0.5)),\n",
        "]\n",
        "\n",
        "features = []\n",
        "names = []\n",
        "\n",
        "for name, ch in channels:\n",
        "    f = channel_to_feature(ch)\n",
        "    names.append(name)\n",
        "    features.append(f)\n",
        "\n",
        "# Stack features into matrix\n",
        "X = np.vstack(features)\n",
        "\n",
        "# Predict\n",
        "preds = model.predict(X)\n",
        "\n",
        "# Optional: prediction probabilities\n",
        "if hasattr(model, \"predict_proba\"):\n",
        "    probs = model.predict_proba(X)\n",
        "else:\n",
        "    probs = None\n",
        "\n",
        "# Create results DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'channel': names,\n",
        "    'prediction': preds\n",
        "})\n",
        "\n",
        "# Add confidence columns if available\n",
        "if probs is not None:\n",
        "    for i, cls in enumerate(model.classes_):\n",
        "        df[f'prob_{cls}'] = probs[:, i]\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-lKtrCIy3kGh",
        "outputId": "7365b6d3-2a29-43c8-c331-1ead044f0fc8"
      },
      "id": "-lKtrCIy3kGh",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             channel         prediction  prob_amplitude_damping  \\\n",
              "0  depolarizing_p0.1       depolarizing                0.120000   \n",
              "1  depolarizing_p0.5       depolarizing                0.000000   \n",
              "2       amp_damp_0.1  amplitude_damping                0.946667   \n",
              "3       amp_damp_0.5  amplitude_damping                0.993333   \n",
              "\n",
              "   prob_depolarizing  \n",
              "0           0.880000  \n",
              "1           1.000000  \n",
              "2           0.053333  \n",
              "3           0.006667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed0ef791-7149-4731-9864-8efc375a65f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel</th>\n",
              "      <th>prediction</th>\n",
              "      <th>prob_amplitude_damping</th>\n",
              "      <th>prob_depolarizing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>depolarizing_p0.1</td>\n",
              "      <td>depolarizing</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>depolarizing_p0.5</td>\n",
              "      <td>depolarizing</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amp_damp_0.1</td>\n",
              "      <td>amplitude_damping</td>\n",
              "      <td>0.946667</td>\n",
              "      <td>0.053333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amp_damp_0.5</td>\n",
              "      <td>amplitude_damping</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>0.006667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed0ef791-7149-4731-9864-8efc375a65f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed0ef791-7149-4731-9864-8efc375a65f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed0ef791-7149-4731-9864-8efc375a65f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c435c550-3e39-4f1e-96d8-db47cfb1f106\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c435c550-3e39-4f1e-96d8-db47cfb1f106 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"channel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"depolarizing_p0.5\",\n          \"amp_damp_0.5\",\n          \"depolarizing_p0.1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"amplitude_damping\",\n          \"depolarizing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_amplitude_damping\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5280116440915827,\n        \"min\": 0.0,\n        \"max\": 0.9933333333333333,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          0.9933333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_depolarizing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5280116440915829,\n        \"min\": 0.006666666666666667,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          0.006666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cfa933d",
      "metadata": {
        "id": "7cfa933d"
      },
      "source": [
        "### Submission checklist\n",
        "- Update `model_path` with the actual artifact you trained in Assignment 3 and note the load result.\n",
        "- Mention any feature changes you make so the classifier stays compatible with production runs.\n",
        "- Save this notebook with outputs after running Tasks 1–5 and add a short reflection in your report."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}